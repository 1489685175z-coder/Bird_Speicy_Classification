{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1489685175z-coder/Bird_Speicy_Classification/blob/main/Bird_Speicy_Classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Project: Fine-Grained Bird Species Classification on CUB-200-2011\n",
        "# Compare: Pretrained ResNet-18 vs Simple CNN from scratch (baseline)\n",
        "# Dataset: bentrevett/caltech-ucsd-birds-200-2011 from Hugging Face\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Import libraries\n",
        "# =============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models, transforms\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SAhzoagBUzvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 2. Device & Hyperparameters\n",
        "# =============================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device：{device}\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20\n",
        "NUM_CLASSES = 200\n",
        "\n",
        "models_config = [\n",
        "    {\"name\": \"resnet18\",   \"pretrained\": True,  \"lr\": 0.001},\n",
        "    {\"name\": \"simple_cnn\", \"pretrained\": False, \"lr\": 0.01}\n",
        "]"
      ],
      "metadata": {
        "id": "pdR2kEouUz8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 3. Load Dataset from Hugging Face\n",
        "# =============================================================================\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "hf_dataset = load_dataset(\"bentrevett/caltech-ucsd-birds-200-2011\")\n",
        "\n",
        "class CUBDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, hf_dataset, transform=None):\n",
        "        self.hf_dataset = hf_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hf_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.hf_dataset[idx]\n",
        "        image = item['image'].convert('RGB')\n",
        "        label = item['label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "full_train_ds = CUBDataset(hf_dataset['train'], train_transform)\n",
        "test_ds = CUBDataset(hf_dataset['test'], test_transform)\n",
        "\n",
        "train_size = int(0.85 * len(full_train_ds))\n",
        "val_size = len(full_train_ds) - train_size\n",
        "train_ds, val_ds = random_split(full_train_ds, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=device.type=='cuda')\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=device.type=='cuda')\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=device.type=='cuda')\n",
        "\n",
        "print(f\"Train samples: {len(train_ds)}, Val samples: {len(val_ds)}, Test samples: {len(test_ds)}\")"
      ],
      "metadata": {
        "id": "dSLuNgbqUz-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 4.Train and Evaluate Function\n",
        "# =============================================================================\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in tqdm(loader, desc=\"训练中\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return running_loss / len(loader), correct / total\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc=\"评估中\"):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    return accuracy_score(all_labels, all_preds)"
      ],
      "metadata": {
        "id": "MLIaNfblU0Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 5. Main Training Loop\n",
        "# =============================================================================\n",
        "all_history = {}\n",
        "test_results = {}\n",
        "\n",
        "for config in models_config:\n",
        "    name = config[\"name\"]\n",
        "    print(f\"\\n===== Training {name} =====\")\n",
        "\n",
        "    if name == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=config[\"pretrained\"])\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "        for param in model.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif name == \"simple_cnn\":\n",
        "        class SimpleCNN(nn.Module):\n",
        "            def __init__(self, num_classes=200):\n",
        "                super().__init__()\n",
        "                self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "                self.pool = nn.MaxPool2d(2, 2)\n",
        "                self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "                self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "                self.flatten = nn.Flatten()\n",
        "                self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "                self.dropout = nn.Dropout(0.5)\n",
        "                self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.conv1(x)); x = self.pool(x)\n",
        "                x = torch.relu(self.conv2(x)); x = self.pool(x)\n",
        "                x = torch.relu(self.conv3(x)); x = self.pool(x)\n",
        "                x = self.flatten(x)\n",
        "                x = torch.relu(self.fc1(x))\n",
        "                x = self.dropout(x)\n",
        "                x = self.fc2(x)\n",
        "                return x\n",
        "\n",
        "        model = SimpleCNN(NUM_CLASSES)\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()) if name == \"resnet18\" else model.parameters(),\n",
        "        lr=config[\"lr\"]\n",
        "    )\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "    best_val = 0.0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        tr_loss, tr_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        va_acc = evaluate(model, val_loader, device)\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"train_acc\"].append(tr_acc)\n",
        "        history[\"val_acc\"].append(va_acc)\n",
        "\n",
        "        print(f\"[{name}] Epoch {epoch+1:2d}/{NUM_EPOCHS} | Loss: {tr_loss:.4f} | Tr Acc: {tr_acc:.4f} | Val Acc: {va_acc:.4f}\")\n",
        "\n",
        "        scheduler.step(va_acc)\n",
        "\n",
        "        if va_acc > best_val:\n",
        "            best_val = va_acc\n",
        "            torch.save(model.state_dict(), f\"best_{name}.pth\")\n",
        "\n",
        "    model.load_state_dict(torch.load(f\"best_{name}.pth\", map_location=device))\n",
        "    test_acc = evaluate(model, test_loader, device)\n",
        "    test_results[name] = test_acc\n",
        "    all_history[name] = history\n",
        "    print(f\"[{name}] Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\\n\")"
      ],
      "metadata": {
        "id": "JVWV1YaZU0LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 6. Plot training curves comparison\n",
        "# =============================================================================\n",
        "epochs_range = range(1, NUM_EPOCHS + 1)\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "for name, h in all_history.items():\n",
        "    plt.plot(epochs_range, h[\"train_loss\"], label=name, marker='o')\n",
        "plt.title(\"Training Loss Curves\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "for name, h in all_history.items():\n",
        "    plt.plot(epochs_range, h[\"train_acc\"], label=name, marker='o')\n",
        "plt.title(\"Training Accuracy Curves\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "for name, h in all_history.items():\n",
        "    plt.plot(epochs_range, h[\"val_acc\"], label=name, marker='o', linewidth=2)\n",
        "plt.title(\"Validation Accuracy Comparison (ResNet-18 vs SimpleCNN)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Val Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n===== Final Comparison Results =====\")\n",
        "for name, acc in test_results.items():\n",
        "    print(f\"{name:12} Test Acc: {acc:.4f} ({acc*100:5.2f}%)\")"
      ],
      "metadata": {
        "id": "fJ35mgI1U0No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# 7.Error Analysis & Confusion Matrix\n",
        "# =============================================\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load bird class names\n",
        "class_names = hf_dataset['train'].features['label'].names\n",
        "print(f\"Loaded {len(class_names)} bird species names (example: {class_names[0]}, {class_names[1]})\")\n",
        "\n",
        "for config in models_config:\n",
        "    name = config[\"name\"]\n",
        "    print(f\"\\n===== Error Analysis & Visualization for {name} =====\")\n",
        "\n",
        "    # Rebuild model structure\n",
        "    if name == \"resnet18\":\n",
        "        model = models.resnet18(pretrained=False)\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, NUM_CLASSES)\n",
        "    elif name == \"simple_cnn\":\n",
        "        class SimpleCNN(nn.Module):\n",
        "            def __init__(self, num_classes=200):\n",
        "                super().__init__()\n",
        "                self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "                self.pool = nn.MaxPool2d(2, 2)\n",
        "                self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "                self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "                self.flatten = nn.Flatten()\n",
        "                self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "                self.dropout = nn.Dropout(0.5)\n",
        "                self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.conv1(x)); x = self.pool(x)\n",
        "                x = torch.relu(self.conv2(x)); x = self.pool(x)\n",
        "                x = torch.relu(self.conv3(x)); x = self.pool(x)\n",
        "                x = self.flatten(x)\n",
        "                x = torch.relu(self.fc1(x))\n",
        "                x = self.dropout(x)\n",
        "                x = self.fc2(x)\n",
        "                return x\n",
        "\n",
        "        model = SimpleCNN(NUM_CLASSES)\n",
        "\n",
        "    # Load best weights\n",
        "    model.load_state_dict(torch.load(f\"best_{name}.pth\", map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Collect predictions and labels\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=f\"[{name}] Collecting predictions\"):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    # 1. Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=False, cmap='Blues', fmt='d')\n",
        "    plt.title(f'Confusion Matrix on Test Set - {name}')\n",
        "    plt.xlabel('Predicted Class')\n",
        "    plt.ylabel('True Class')\n",
        "    plt.savefig(f'confusion_matrix_{name}.png', dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Top 5 most confused pairs\n",
        "    errors = [(true, pred) for true, pred in zip(all_labels, all_preds) if true != pred]\n",
        "\n",
        "    if errors:\n",
        "        most_common_errors = Counter(errors).most_common(5)\n",
        "        print(\"Top 5 most confused bird pairs (True → Predicted):\")\n",
        "        for (true_label, pred_label), count in most_common_errors:\n",
        "            true_name = class_names[true_label]\n",
        "            pred_name = class_names[pred_label]\n",
        "            print(f\"  {true_name} → {pred_name} : {count} times\")\n",
        "    else:\n",
        "        print(\"No errors found! (Perfect prediction - unlikely)\")\n",
        "\n",
        "    # 3. Visualize first 9 misclassified samples\n",
        "    wrong_idx = np.where(np.array(all_preds) != np.array(all_labels))[0]\n",
        "    print(f\"[{name}] Number of misclassified samples: {len(wrong_idx)}\")\n",
        "\n",
        "    show_n = min(9, len(wrong_idx))\n",
        "    if show_n > 0:\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(14, 14))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        # Collect denormalized images for wrong indices\n",
        "        mis_images = []\n",
        "        sample_idx = 0\n",
        "        collected = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_images, _ in test_loader:\n",
        "                for img_tensor in batch_images:\n",
        "                    if sample_idx in wrong_idx[:show_n]:\n",
        "                        # Denormalize\n",
        "                        img = img_tensor.cpu().numpy()  # [3, H, W]\n",
        "                        img = np.transpose(img, (1, 2, 0))  # [H, W, 3]\n",
        "                        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                        img = np.clip(img, 0, 1)\n",
        "                        mis_images.append(img)\n",
        "                        collected += 1\n",
        "                    sample_idx += 1\n",
        "                    if collected >= show_n:\n",
        "                        break\n",
        "                if collected >= show_n:\n",
        "                    break\n",
        "\n",
        "        # Display\n",
        "        for i in range(show_n):\n",
        "            axes[i].imshow(mis_images[i])\n",
        "            true_name = class_names[all_labels[wrong_idx[i]]]\n",
        "            pred_name = class_names[all_preds[wrong_idx[i]]]\n",
        "            axes[i].set_title(f\"True: {true_name}\\nPred: {pred_name}\", fontsize=10)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        for j in range(show_n, 9):\n",
        "            axes[j].axis('off')\n",
        "\n",
        "        plt.suptitle(f\"Misclassified Examples - {name} (First {show_n})\", fontsize=16)\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"[{name}] No misclassified samples to display.\")\n",
        "\n",
        "    # Re-compute accuracy for confirmation\n",
        "    test_acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"[{name}] Test Accuracy (re-computed): {test_acc:.4f} ({test_acc*100:.2f}%)\\n\")"
      ],
      "metadata": {
        "id": "OvOrSrgM0dEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}